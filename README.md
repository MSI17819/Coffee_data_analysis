# Project Name
### Coffee data analysis

## Table of Contents
* [General Info](#general-information)
* [Dataset](#dataset)
* [Technology stack](#technology_stack)
* [Project Status](#project-status)
* [Room for Improvement](#room-for-improvement)
* [Acknowledgements](#acknowledgements)
* [Contact](#contact)
<!-- * [License](#license) -->

## General Information
Simple coffee data analysis from datset available from ICO (International Coffee Organization) website [link](https://www.ico.org/new_historical.asp)

Data were upload for ICO website and preprocessed to csv file.

Notebook with all preprocessing steps:
- web scrapping function
- data preprocessing and cleaning
- export data to csv file 

Is stored in [link](https://github.com/MSI17819/Coffee_data_analysis/blob/codeimpro/Coffee_codeimpro.ipynb)

## Dataset

The dataset is available in my Kaggel account [link](https://www.kaggle.com/datasets/michals22/coffee-dataset)

#### 1) Dataset contain information

Dataset contain information about coffee production, consumption, export, re-export in each year from 1990 to 2020.

#### 2) Dataset for analysis

The dataset is available in a csv file [link](https://www.kaggle.com/datasets/michals22/coffee-dataset)

## Technology stack

### Computing platform

- [Miniconda environment](https://docs.conda.io/en/latest/miniconda.html)
- [Jupyter Notebook](https://jupyter.org/)
- [PyCharm](https://www.jetbrains.com/pycharm/)

### Packages for data pre-processing

- [Numpy](https://numpy.org/)
- [Pandas](https://numpy.org/)

### Data visualisation library

- [Matplotlib](https://matplotlib.org/)
- [Seaborn](https://seaborn.pydata.org/)

## Project status

Project is: *completed*

## Room for Improvement

In the future, the project can be improved by:
- adding more data from more other sources
- adding more analyses by region or country level  
- extending the dataset not only to coffee, but also to products such as tea or yerba mate

## Acknowledgements


## Contact


Created by *123michal86@gmail.com* - feel free to contact me!
